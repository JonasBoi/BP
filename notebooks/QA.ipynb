{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptvBUgFZkKmm"
      },
      "source": [
        "# Requirments\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUgwJtaFLYTc"
      },
      "source": [
        "\"\"\"\r\n",
        "# get majka database\r\n",
        "!curl --remote-name-all https://nlp.fi.muni.cz/ma{/majka.w-lt}\r\n",
        "!mv majka.w-lt drive/MyDrive/data/\r\n",
        "# download czech squad\r\n",
        "!curl --remote-name-all https://lindat.cz/repository/xmlui/bitstream/handle/11234/1-3069{/sqad_v3.tar.xz}\r\n",
        "!mv sqad_v3.tar.xz drive/MyDrive/data/\r\n",
        "!tar -xf drive/MyDrive/data/sqad_v3.tar.xz\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKgj8CeSViAh"
      },
      "source": [
        "!pip install sentencepiece\r\n",
        "!pip install datasets transformers\r\n",
        "!pip install googletrans==4.0.0-rc1\r\n",
        "!pip install wikipedia\r\n",
        "!pip install rank_bm25\r\n",
        "!pip install majka"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRQGzm8pJ4C6"
      },
      "source": [
        "import torch\r\n",
        "import string\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import time\r\n",
        "import shutil\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import collections\r\n",
        "import datetime\r\n",
        "from tqdm.auto import tqdm\r\n",
        "import warnings\r\n",
        "\r\n",
        "from datasets import load_dataset, load_metric\r\n",
        "from typing import List, Tuple, Dict\r\n",
        "from collections import defaultdict\r\n",
        "from transformers import AlbertTokenizerFast, AlbertForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\r\n",
        "\r\n",
        "from rank_bm25 import BM25Okapi, BM25Plus, BM25L\r\n",
        "import re\r\n",
        "import majka\r\n",
        "import wikipedia\r\n",
        "from googletrans import Translator\r\n",
        "import requests\r\n",
        "\r\n",
        "\r\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oFuZPSCKZiv"
      },
      "source": [
        "# Remove pre-cached sample data in colab's directory\r\n",
        "if os.path.isdir(\"sample_data\"):\r\n",
        "  shutil.rmtree(\"sample_data\")\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcgjqBzMoitL"
      },
      "source": [
        "Print gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWWMtqQ-rf5z"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vES2bhXy4Z7"
      },
      "source": [
        "# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible\r\n",
        "# answers are allowed or not).\r\n",
        "squad_v2 = True\r\n",
        "if squad_v2:\r\n",
        "  model_checkpoint = \"./drive/MyDrive/albert_models/albert_squad2_finetuned\"\r\n",
        "else:\r\n",
        "  model_checkpoint = \"./drive/MyDrive/albert_models/albert_finetuned\"\r\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TshLGyuzEUpf"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT-5_Hse4MJA"
      },
      "source": [
        "def prepare_train_features(examples):\r\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\r\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\r\n",
        "    # context that overlaps a bit the context of the previous feature.\r\n",
        "    tokenized_examples = tokenizer(\r\n",
        "        examples[\"question\"],\r\n",
        "        examples[\"context\"],\r\n",
        "        truncation=\"only_second\",\r\n",
        "        max_length=max_length,\r\n",
        "        stride=doc_stride,\r\n",
        "        return_overflowing_tokens=True,\r\n",
        "        return_offsets_mapping=True,\r\n",
        "        padding=\"max_length\",\r\n",
        "    )\r\n",
        "\r\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\r\n",
        "    # its corresponding example. This key gives us just that.\r\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\r\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\r\n",
        "    # help us compute the start_positions and end_positions.\r\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\r\n",
        "\r\n",
        "    # Let's label those examples!\r\n",
        "    tokenized_examples[\"start_positions\"] = []\r\n",
        "    tokenized_examples[\"end_positions\"] = []\r\n",
        "\r\n",
        "    for i, offsets in enumerate(offset_mapping):\r\n",
        "        # We will label impossible answers with the index of the CLS token.\r\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\r\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\r\n",
        "\r\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\r\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\r\n",
        "\r\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\r\n",
        "        sample_index = sample_mapping[i]\r\n",
        "        answers = examples[\"answers\"][sample_index]\r\n",
        "        # If no answers are given, set the cls_index as answer.\r\n",
        "        if len(answers[\"answer_start\"]) == 0:\r\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\r\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\r\n",
        "        else:\r\n",
        "            # Start/end character index of the answer in the text.\r\n",
        "            start_char = answers[\"answer_start\"][0]\r\n",
        "            end_char = start_char + len(answers[\"text\"][0])\r\n",
        "\r\n",
        "            # Start token index of the current span in the text.\r\n",
        "            token_start_index = 0\r\n",
        "            while sequence_ids[token_start_index] != 1:\r\n",
        "                token_start_index += 1\r\n",
        "\r\n",
        "            # End token index of the current span in the text.\r\n",
        "            token_end_index = len(input_ids) - 1\r\n",
        "            while sequence_ids[token_end_index] != 1:\r\n",
        "                token_end_index -= 1\r\n",
        "\r\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\r\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\r\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\r\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\r\n",
        "            else:\r\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\r\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\r\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\r\n",
        "                    token_start_index += 1\r\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\r\n",
        "                while offsets[token_end_index][1] >= end_char:\r\n",
        "                    token_end_index -= 1\r\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\r\n",
        "\r\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKlUfZ_nBzkL"
      },
      "source": [
        "tokenizer = AlbertTokenizerFast.from_pretrained(model_checkpoint)\r\n",
        "datasets = load_dataset(\"squad_v2\" if squad_v2 else \"squad\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd4irRm65p06"
      },
      "source": [
        "max_length=384\r\n",
        "doc_stride=128\r\n",
        "tokenized_datasets = datasets.map(prepare_train_features,\r\n",
        "                                  batched=True, \r\n",
        "                                  remove_columns=datasets[\"train\"].column_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N3VXCshEY3g"
      },
      "source": [
        "# Model fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxulpn9Q770q"
      },
      "source": [
        "model = AlbertForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzVL6NbxZREF"
      },
      "source": [
        "Create trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ03rHLM8MZ6"
      },
      "source": [
        "args = TrainingArguments(\r\n",
        "    f\"./drive/MyDrive/data/checkpoints\",\r\n",
        "    evaluation_strategy = \"epoch\",\r\n",
        "    learning_rate=2e-5,\r\n",
        "    per_device_train_batch_size=batch_size,\r\n",
        "    per_device_eval_batch_size=batch_size,\r\n",
        "    num_train_epochs=3,\r\n",
        "    weight_decay=0.01,\r\n",
        ")\r\n",
        "\r\n",
        "data_collator = default_data_collator\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model,\r\n",
        "    args,\r\n",
        "    train_dataset=tokenized_datasets[\"train\"],\r\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\r\n",
        "    data_collator=data_collator,\r\n",
        "    tokenizer=tokenizer,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esdYGARYZz73"
      },
      "source": [
        "Train and save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBZMu-OB82D2"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fps_UYycBQSF"
      },
      "source": [
        "trainer.save_model(\"./drive/MyDrive/data/albert_finetuned\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYPwBfguEgAb"
      },
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biBzgvjUS54U"
      },
      "source": [
        "def prepare_validation_features(examples):\r\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\r\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\r\n",
        "    # context that overlaps a bit the context of the previous feature.\r\n",
        "    tokenized_examples = tokenizer(\r\n",
        "        examples[\"question\"],\r\n",
        "        examples[\"context\"],\r\n",
        "        truncation=\"only_second\",\r\n",
        "        max_length=max_length,\r\n",
        "        stride=doc_stride,\r\n",
        "        return_overflowing_tokens=True,\r\n",
        "        return_offsets_mapping=True,\r\n",
        "        padding=\"max_length\",\r\n",
        "    )\r\n",
        "\r\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\r\n",
        "    # its corresponding example. This key gives us just that.\r\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\r\n",
        "\r\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\r\n",
        "    tokenized_examples[\"example_id\"] = []\r\n",
        "\r\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\r\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\r\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\r\n",
        "        context_index = 1\r\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\r\n",
        "        sample_index = sample_mapping[i]\r\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\r\n",
        "\r\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\r\n",
        "        # position is part of the context or not.\r\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\r\n",
        "            (o if sequence_ids[k] == context_index else None)\r\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\r\n",
        "        ]\r\n",
        "\r\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmK8WQLEWyRN"
      },
      "source": [
        "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\r\n",
        "    all_start_logits, all_end_logits = raw_predictions\r\n",
        "    # Build a map example to its corresponding features.\r\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\r\n",
        "    features_per_example = collections.defaultdict(list)\r\n",
        "    for i, feature in enumerate(features):\r\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\r\n",
        "\r\n",
        "    # The dictionaries we have to fill.\r\n",
        "    predictions = collections.OrderedDict()\r\n",
        "\r\n",
        "    # Logging.\r\n",
        "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\r\n",
        "\r\n",
        "    # Let's loop over all the examples!\r\n",
        "    for example_index, example in enumerate(tqdm(examples)):\r\n",
        "        # Those are the indices of the features associated to the current example.\r\n",
        "        feature_indices = features_per_example[example_index]\r\n",
        "\r\n",
        "        min_null_score = None # Only used if squad_v2 is True.\r\n",
        "        valid_answers = []\r\n",
        "        \r\n",
        "        context = example[\"context\"]\r\n",
        "        # Looping through all the features associated to the current example.\r\n",
        "        for feature_index in feature_indices:\r\n",
        "            # We grab the predictions of the model for this feature.\r\n",
        "            start_logits = all_start_logits[feature_index]\r\n",
        "            end_logits = all_end_logits[feature_index]\r\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\r\n",
        "            # context.\r\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\r\n",
        "\r\n",
        "            # Update minimum null prediction.\r\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\r\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\r\n",
        "            if min_null_score is None or min_null_score < feature_null_score:\r\n",
        "                min_null_score = feature_null_score\r\n",
        "\r\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\r\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\r\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\r\n",
        "            for start_index in start_indexes:\r\n",
        "                for end_index in end_indexes:\r\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\r\n",
        "                    # to part of the input_ids that are not in the context.\r\n",
        "                    if (\r\n",
        "                        start_index >= len(offset_mapping)\r\n",
        "                        or end_index >= len(offset_mapping)\r\n",
        "                        or offset_mapping[start_index] is None\r\n",
        "                        or offset_mapping[end_index] is None\r\n",
        "                    ):\r\n",
        "                        continue\r\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\r\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\r\n",
        "                        continue\r\n",
        "\r\n",
        "                    start_char = offset_mapping[start_index][0]\r\n",
        "                    end_char = offset_mapping[end_index][1]\r\n",
        "                    valid_answers.append(\r\n",
        "                        {\r\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\r\n",
        "                            \"text\": context[start_char: end_char]\r\n",
        "                        }\r\n",
        "                    )\r\n",
        "        \r\n",
        "        if len(valid_answers) > 0:\r\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\r\n",
        "        else:\r\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\r\n",
        "            # failure.\r\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\r\n",
        "        \r\n",
        "        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\r\n",
        "        if not squad_v2:\r\n",
        "            predictions[example[\"id\"]] = best_answer[\"text\"]\r\n",
        "        else:\r\n",
        "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\r\n",
        "            predictions[example[\"id\"]] = answer\r\n",
        "\r\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCkrrwoTYWCN"
      },
      "source": [
        "Final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lse-A4J-U7-g"
      },
      "source": [
        "# get ground truth features\r\n",
        "validation_features = datasets[\"validation\"].map(prepare_validation_features,\r\n",
        "                                                 batched=True,\r\n",
        "                                                 remove_columns=datasets[\"validation\"].column_names)\r\n",
        "\r\n",
        "# get raw predictions\r\n",
        "raw_predictions = trainer.predict(validation_features)\r\n",
        "\r\n",
        "validation_features.set_format(type=validation_features.format[\"type\"], \r\n",
        "                               columns=list(validation_features.features.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrYmOc4UYBcB"
      },
      "source": [
        "# hyperparameters\r\n",
        "max_answer_length = 30\r\n",
        "n_best_size = 20\r\n",
        "\r\n",
        "# map examples to features\r\n",
        "examples = datasets[\"validation\"]\r\n",
        "features = validation_features\r\n",
        "\r\n",
        "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\r\n",
        "features_per_example = collections.defaultdict(list)\r\n",
        "for i, feature in enumerate(features):\r\n",
        "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\r\n",
        "\r\n",
        "# get final predictions\r\n",
        "final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)\r\n",
        "# get metric used\r\n",
        "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\r\n",
        "\r\n",
        "#evaluate\r\n",
        "if squad_v2:\r\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\r\n",
        "else:\r\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\r\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\r\n",
        "metric.compute(predictions=formatted_predictions, references=references)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPGazghDdOXn"
      },
      "source": [
        "# Decode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZgfE6VfdQBF"
      },
      "source": [
        "def decode(output, context, offset_mappings):\r\n",
        "  # hyperparameters\r\n",
        "  max_answer_length = 10\r\n",
        "  n_best_size = 10\r\n",
        "  \r\n",
        "  # enumerate over all outputs (max output size is 500 tokens in a log prob tensor)\r\n",
        "  valid_answers = []\r\n",
        "  for i, _ in enumerate(output.start_logits):\r\n",
        "\r\n",
        "    start_logits = output.start_logits[i].cpu().detach().numpy()\r\n",
        "    end_logits = output.end_logits[i].cpu().detach().numpy()\r\n",
        "    offset_mapping = offset_mappings[i]\r\n",
        "\r\n",
        "    # Gather the indices the best start/end logits:\r\n",
        "    start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\r\n",
        "    end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\r\n",
        "    for start_index in start_indexes:\r\n",
        "        for end_index in end_indexes:\r\n",
        "            # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\r\n",
        "            # to part of the input_ids that are not in the context.\r\n",
        "            if (\r\n",
        "                start_index >= len(offset_mapping)\r\n",
        "                or end_index >= len(offset_mapping)\r\n",
        "                or offset_mapping[start_index] is None\r\n",
        "                or offset_mapping[end_index] is None\r\n",
        "            ):\r\n",
        "                continue\r\n",
        "            # Don't consider answers with a length that is either < 0 or > max_answer_length.\r\n",
        "            if end_index < start_index or end_index - start_index + 1 > max_answer_length:\r\n",
        "                continue\r\n",
        "            if start_index <= end_index: # We need to refine that test to check the answer is inside the context\r\n",
        "                start_char = offset_mapping[start_index][0]\r\n",
        "                end_char = offset_mapping[end_index][1]\r\n",
        "                valid_answers.append(\r\n",
        "                    {\r\n",
        "                        \"score\": start_logits[start_index] + end_logits[end_index],\r\n",
        "                        \"text\": context[start_char: end_char].strip()\r\n",
        "                    }\r\n",
        "                )\r\n",
        "\r\n",
        "  valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\r\n",
        "  return valid_answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dmVBkIRlCT-"
      },
      "source": [
        "Get answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl5IA55IlEGx"
      },
      "source": [
        "def get_answers(question, context):\r\n",
        "  inputs = tokenizer(question, context, \r\n",
        "                     return_tensors='pt',\r\n",
        "                     truncation=\"only_second\",\r\n",
        "                     max_length=384, # to prevent cuda running out of memory\r\n",
        "                     stride=128,     # overlap within splitted long\r\n",
        "                     return_offsets_mapping=True,\r\n",
        "                     return_overflowing_tokens=True,\r\n",
        "                     padding=\"max_length\")\r\n",
        "  inputs.to(device)\r\n",
        "\r\n",
        "  outputs = model(inputs['input_ids'], \r\n",
        "                  token_type_ids=inputs['token_type_ids'],\r\n",
        "                  attention_mask=inputs['attention_mask'])\r\n",
        "  \r\n",
        "  valid_answers = decode(outputs, context, inputs['offset_mapping'])\r\n",
        "  return valid_answers # [0]['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31IV1omUfXNP"
      },
      "source": [
        "# Loading model\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d3vTvLMn4ua"
      },
      "source": [
        "Choose trained version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9-UEUNjnGsm"
      },
      "source": [
        "squad_v2 = False\r\n",
        "if squad_v2:\r\n",
        "  model_checkpoint = \"./drive/MyDrive/albert_models/albert_squad2_finetuned\"\r\n",
        "else:\r\n",
        "  model_checkpoint = \"./drive/MyDrive/albert_models/albert_finetuned\"\r\n",
        "\r\n",
        "# model_checkpoint = \"ktrapeznikov/albert-xlarge-v2-squad-v2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8fIHfAgn7Oh"
      },
      "source": [
        "Load model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A1KQGXAkbdZ"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained(model_checkpoint)\n",
        "model = AlbertForQuestionAnswering.from_pretrained(model_checkpoint).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWjuG8EAyz4u"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "print(f\"Model has {count_parameters(model)} parameters\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whlGzus9Z4Tx"
      },
      "source": [
        "# Retriever\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v9Zm6xex7VX"
      },
      "source": [
        "translator = Translator()\r\n",
        "wikipedia.set_lang(\"cs\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJuYvKQbfIl0"
      },
      "source": [
        "Build index for searching through relevant title names on czech wiki:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J2bXj3fexS6"
      },
      "source": [
        "def get_title_search_index():\r\n",
        "  f = open(\"drive/MyDrive/data/wiki/cswiki-latest-all-titles-in-ns0\", \"r\")\r\n",
        "  titles = []\r\n",
        "\r\n",
        "  for line in f: \r\n",
        "    title = ((\" \").join(line.split(\"_\"))).strip()\r\n",
        "    title = title.strip('\\n')\r\n",
        "    titles.append(title)\r\n",
        "\r\n",
        "  f.close()\r\n",
        "\r\n",
        "  # tokenize for bm25\r\n",
        "  tok_titles = []\r\n",
        "  for title in titles:\r\n",
        "    tok_tit = re.split(\" \", title.lower())\r\n",
        "    for tok in tok_tit:\r\n",
        "      if tok == \"\":\r\n",
        "        tok_tit.remove(\"\")\r\n",
        "    tok_titles.append(tok_tit)\r\n",
        "\r\n",
        "  bm25 = BM25Okapi(tok_titles)\r\n",
        "\r\n",
        "  return bm25, titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEI9hhDFfel9"
      },
      "source": [
        "def search_titles(question, bm25, titles):\r\n",
        "  tokenized_query = delete_common(lemmatize(question.lower()))\r\n",
        "  # print(tokenized_query)\r\n",
        "  results = bm25.get_top_n(tokenized_query, titles, n=5)\r\n",
        "\r\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAwf6015fWYm"
      },
      "source": [
        "Extract named entities' lemmatas from question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue6TDcFal2IT"
      },
      "source": [
        "def getNamed_ER(question):\r\n",
        "  \"\"\"\r\n",
        "  Extracts named entities from the question.\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  URL = \"https://nlp.fi.muni.cz/projekty/ner/nerJSON.py\"\r\n",
        "  text = question\r\n",
        "  PARAMS = {'text': text}\r\n",
        "  r = requests.get(url = URL, params = PARAMS)\r\n",
        "  data = r.json() \r\n",
        "\r\n",
        "  lemmatas = []\r\n",
        "\r\n",
        "  if data != {}:\r\n",
        "    for item in data:\r\n",
        "      lemma = data[item]['lemma']\r\n",
        "      lemmatas.append(lemma)\r\n",
        "\r\n",
        "  return lemmatas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrJsP4y_p7P-"
      },
      "source": [
        "def extract_que_ans(dirnum, filename, lemmatized=False):\r\n",
        "  # get question and answer from czech squad \r\n",
        "  f = open(f\"drive/MyDrive/data/cz_sqad/data/{dirnum}/{filename}\", \"r\")\r\n",
        "  q = f.read().split(\"\\n\")\r\n",
        "  question = \"\"\r\n",
        "\r\n",
        "  #lemmatized parsed\r\n",
        "  if lemmatized:\r\n",
        "    answer = \"\"\r\n",
        "    for line in q:\r\n",
        "      if len(line.split()) < 2:\r\n",
        "        continue\r\n",
        "      line = line.split(\"\\t\")[1]\r\n",
        "      if line in {\"<s>\", \"<g/>\", \"</s>\"}:\r\n",
        "        answer = answer[:-1]\r\n",
        "        continue\r\n",
        "      if line != \"?\":\r\n",
        "        answer += line + \" \"\r\n",
        "      else:\r\n",
        "        answer += \" ? \"\r\n",
        "\r\n",
        "    f.close()\r\n",
        "    return answer\r\n",
        "\r\n",
        "  # normal parse\r\n",
        "  for line in q:\r\n",
        "    line = line.split(\"\\t\")[0]\r\n",
        "    if line in {\"<s>\", \"<g/>\", \"</s>\"}:\r\n",
        "      question = question[:-1]\r\n",
        "      continue\r\n",
        "    \r\n",
        "    if line != \"?\":\r\n",
        "      question += line + \" \"\r\n",
        "    else:\r\n",
        "      question += \" ? \"\r\n",
        "\r\n",
        "  f.close()\r\n",
        "  return question"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPfhmPY-xO85"
      },
      "source": [
        "# save the most common czech words\r\n",
        "# common = \"být a se v na ten on že s z který mít do já o k i jeho ale svůj jako za moci rok pro tak po tento co když všechen už jak aby od nebo říci jeden jen můj jenž člověk ty stát u muset velký chtít také až než ještě při jít pak před dva však ani vědět nový hodně podle další celý jiný mezi dát tady den tam kde doba každý místo dobrý takový strana protože nic začít něco vidět říkat ne sám bez či dostat nějaký proto\"\r\n",
        "common = \"kdy být a se v na ten on že s z který mít do já o k i jeho ale svůj jako za moci pro tak po tento co když všechen už jak aby od nebo říci jeden jen můj jenž ty stát u muset chtít také až než ještě při jít pak před však ani vědět hodně podle další celý jiný mezi dát tady tam kde každý takový protože nic něco ne sám bez či dostat nějaký proto\"\r\n",
        "common = common.split()\r\n",
        "punctuation = \". , ? ! ... \\\" ( ) ; - /\"\r\n",
        "punctuation = punctuation.split()\r\n",
        "\r\n",
        "# decides if query token is common\r\n",
        "def iscommon(x):\r\n",
        "  if x in common or x in punctuation:\r\n",
        "    return True\r\n",
        "  else:\r\n",
        "    return False\r\n",
        "\r\n",
        "# remove the most common czech words from the query tokens (low information value)\r\n",
        "def delete_common(tokens):\r\n",
        "  tokens = [x for x in tokens if not iscommon(x)]\r\n",
        "      \r\n",
        "  return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oNdBO3PCOjI"
      },
      "source": [
        "def search_again(tokens):\r\n",
        "\r\n",
        "  searched_term = (' ').join(tokens)\r\n",
        "  #print(searched_term)\r\n",
        "  doc_list = wikipedia.search(searched_term, results=1)\r\n",
        "\r\n",
        "  if len(tokens) == 0:\r\n",
        "    return []\r\n",
        "\r\n",
        "  if len(doc_list) == 0:\r\n",
        "    del tokens[0]\r\n",
        "    return search_again(tokens)\r\n",
        "\r\n",
        "  return doc_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXpTErpEr1hN"
      },
      "source": [
        "morph = majka.Majka('drive/MyDrive/data/majka.w-lt')\r\n",
        "morph.flags |= majka.ADD_DIACRITICS  # find word forms with diacritics\r\n",
        "morph.flags |= majka.DISALLOW_LOWERCASE  # do not enable to find lowercase variants\r\n",
        "morph.flags |= majka.IGNORE_CASE  # ignore the word case whatsoever\r\n",
        "morph.flags = 0  # unset all flags\r\n",
        "\r\n",
        "morph.tags = False  # return just the lemma, do not process the tags\r\n",
        "morph.first_only = True  # return only the first entry\r\n",
        "morph.negative = \"ne\"\r\n",
        "\r\n",
        "# returns lemma of each token in a list of lemmatized tokens\r\n",
        "def lemmatize(text):\r\n",
        "\r\n",
        "  tok_text = text.lower()\r\n",
        "  tok_text = re.split(\"\\W\", text)\r\n",
        "\r\n",
        "  # lemmatize each token\r\n",
        "  lemmatized_tokens = []\r\n",
        "  for token in tok_text:\r\n",
        "    if token == '':\r\n",
        "      continue\r\n",
        "    lemma = morph.find(token)\r\n",
        "    if len(lemma) == 0:\r\n",
        "      lemmatized_tokens.append(token)\r\n",
        "    else:\r\n",
        "      lemmatized_tokens.append(lemma[0]['lemma'])\r\n",
        "\r\n",
        "  return lemmatized_tokens\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojH1dZ26jZf3"
      },
      "source": [
        "def get_doc_list(question, bm_articles_index, titles):\r\n",
        "  # get names entities if present\r\n",
        "  named_ERs = getNamed_ER(question)\r\n",
        "  # get relevant article title names\r\n",
        "  relevant_titles = search_titles(question, bm_articles_index, titles)\r\n",
        "\r\n",
        "  #search for documents\r\n",
        "  max_docs = 1\r\n",
        "  doc_list = []\r\n",
        "\r\n",
        "  # search based on recognised named entity\r\n",
        "  if len(named_ERs) > 0:\r\n",
        "    article = wikipedia.search(named_ERs[0], results=max_docs)\r\n",
        "    if len(article) > 0:\r\n",
        "      doc_list.append(article[0])\r\n",
        "  # search based on best wiki title match\r\n",
        "  if len(relevant_titles) > 0:\r\n",
        "    article = wikipedia.search(relevant_titles[0], results=max_docs)\r\n",
        "    if len(article) > 0:\r\n",
        "      doc_list.append(article[0])\r\n",
        "\r\n",
        "  # basic search for the question\r\n",
        "  article = wikipedia.search(question, results=max_docs)\r\n",
        "  # simplify the search if its too bad\r\n",
        "  if len(article) == 0:\r\n",
        "    # extract important for wiki\r\n",
        "    tokens = delete_common(lemmatize(question))\r\n",
        "    article = search_again(tokens)\r\n",
        "  doc_list.append(article[0])\r\n",
        "\r\n",
        "  return doc_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjYaStGxV7tw"
      },
      "source": [
        "def retrieve(question, bm_articles_index, titles):  \r\n",
        "  \"\"\"\r\n",
        "  returns the top 3 paragraphs for the given question\r\n",
        "  \"\"\"\r\n",
        "  question = question.strip('?')\r\n",
        "\r\n",
        "  doc_list = get_doc_list(question, bm_articles_index, titles)\r\n",
        "\r\n",
        "  # CONTROL PRINT######################################\r\n",
        "  print(doc_list)\r\n",
        "\r\n",
        "  # split docs into paragraphs\r\n",
        "  pars = []\r\n",
        "  lemm_pars = []\r\n",
        "\r\n",
        "  for doc in doc_list:\r\n",
        "    # get whole page content\r\n",
        "    try:\r\n",
        "      doc = wikipedia.page(doc)\r\n",
        "    except wikipedia.DisambiguationError as e:\r\n",
        "      s = e.options[0]\r\n",
        "      try:\r\n",
        "        doc = wikipedia.page(s)\r\n",
        "      except wikipedia.DisambiguationError:\r\n",
        "        continue\r\n",
        "    \r\n",
        "    result = re.split('== .*. ==|\\\\n\\\\n', doc.content)\r\n",
        "\r\n",
        "    # save stripped paragraphs\r\n",
        "    for par in result:\r\n",
        "      par = par.strip()\r\n",
        "      par = par.strip('=')\r\n",
        "      par = par.strip('\\n')\r\n",
        "      par = par.strip('\\n\\n')\r\n",
        "      par = par.strip('\\r\\n')\r\n",
        "\r\n",
        "      if par == '' or par == '\\n':\r\n",
        "        continue\r\n",
        "\r\n",
        "      # get lemmas\r\n",
        "      lemm_pars.append((' ').join(delete_common(lemmatize(par.lower()))))\r\n",
        "      pars.append(par)\r\n",
        "\r\n",
        "  # tokenize for bm25\r\n",
        "  tok_text = []\r\n",
        "  for par in lemm_pars:\r\n",
        "    tok_par = par.lower()\r\n",
        "    tok_par = re.split(\"\\W\", tok_par)\r\n",
        "    for tok in tok_par:\r\n",
        "      if tok == \"\":\r\n",
        "        tok_par.remove(\"\")\r\n",
        "    tok_text.append(tok_par)\r\n",
        "\r\n",
        "  # build index\r\n",
        "  # bm25 = BM25L(tok_text)\r\n",
        "  bm25 = BM25Plus(tok_text)\r\n",
        "  # bm25 = BM25Okapi(tok_text)\r\n",
        "\r\n",
        "  # tokenize and lemmatize the query\r\n",
        "  tokenized_query = (' ').join(delete_common(lemmatize(question.lower())))\r\n",
        "  tokenized_query = re.split(\"\\W\", tokenized_query)\r\n",
        "\r\n",
        "  # get results\r\n",
        "  results = bm25.get_top_n(tokenized_query, pars, n=3)\r\n",
        "\r\n",
        "  return results\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjpBFtqWNEcD"
      },
      "source": [
        "def count_log_conf(best_answer, all_answers):\r\n",
        "  log_conf = 0\r\n",
        "  for answer in all_answers:\r\n",
        "    if (best_answer in answer['text']) or (answer['text'] in best_answer):\r\n",
        "      log_conf += answer['score']\r\n",
        "  \r\n",
        "  return log_conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vx4Wp01k0Gl"
      },
      "source": [
        "# Testing with sqad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf9PmQUh3bez"
      },
      "source": [
        "# write results to\r\n",
        "f = open(\"drive/MyDrive/data/saved_answers/saved_answers_albert/1-100_ner_with_info.txt\", \"a\")\r\n",
        "\r\n",
        "# build index for searching through wiki article titles\r\n",
        "bm25_for_title_index, titles = get_title_search_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn5_5_YKeC0w"
      },
      "source": [
        "# write results to\n",
        "f = open(\"drive/MyDrive/data/saved_answers/saved_answers_albert/1-100_ner_with_info.txt\", \"a\")\n",
        "# write first question-answer pairs in sqad\n",
        "from_q = 95\n",
        "to_q = 95\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "for i in range(from_q, to_q+1):\n",
        "\n",
        "  # get question number\n",
        "  name = \"\"\n",
        "  for _ in range(len(str(i)), 6):\n",
        "    name += \"0\"\n",
        "  name += str(i)\n",
        "\n",
        "  # extract from dataset\n",
        "  question = extract_que_ans(name, \"01question.vert\")\n",
        "  correct_answer = extract_que_ans(name, \"09answer_extraction.vert\")\n",
        "  lemmatized_answer = extract_que_ans(name, \"09answer_extraction.vert\", lemmatized=True)\n",
        "\n",
        "  # wiki search\n",
        "  documents = retrieve(question, bm25_for_title_index, titles)\n",
        "\n",
        "  # for saving the best results\n",
        "  bestAnswers = []\n",
        "  bestDocs = []\n",
        "  bestLogProbs = []\n",
        "  bestSummedLogProbs = []\n",
        "\n",
        "  question_cs = question # save czech question\n",
        "\n",
        "  # iterate over retrieved paragraphs\n",
        "  for document in documents:\n",
        "\n",
        "    # strip whitespaces\n",
        "    document = document.strip()\n",
        "\n",
        "    # chceck if any document has been found for the question\n",
        "    if document == \"\":\n",
        "      f.write(\"question: \" + question + \"\\n\" +\n",
        "              \"answer: odpověď nenalezena\" + \"\\n\" + \n",
        "              \"correct answer: \" + correct_answer + \"\\n\\n\")\n",
        "      continue;\n",
        "    try:\n",
        "      document_cs = document\n",
        "      document = translator.translate(document, src='cs', dest='en').text\n",
        "    except TypeError:\n",
        "      continue\n",
        "\n",
        "    # remove some trash\n",
        "    # TODO this not cool (in retriever)\n",
        "    if (document_cs.strip().startswith(\"Obrázky, zvuky či videa k tématu\")):\n",
        "      continue\n",
        "\n",
        "    bestDocs.append(document_cs)\n",
        "    # translate\n",
        "    question = translator.translate(question, src='cs', dest='en').text\n",
        "\n",
        "    #get answer -------------------------------------------\n",
        "    answers = get_answers(question, document)\n",
        "    log_conf = 0\n",
        "    answer = ''\n",
        "\n",
        "    for answer in answers:\n",
        "      if answer['text'] != '':\n",
        "        log_conf = answer['score']\n",
        "        answer = answer['text']\n",
        "        log_conf_summed = count_log_conf(answer, answers)\n",
        "        break\n",
        "    #######################################################\n",
        "\n",
        "    # save probs and answer\n",
        "    bestAnswers.append(answer)\n",
        "    bestLogProbs.append(log_conf)\n",
        "    bestSummedLogProbs.append(log_conf_summed)\n",
        "\n",
        "  # check if any answer was found\n",
        "  if len(bestLogProbs) == 0 or bestAnswers[np.argmax(bestLogProbs, axis=0)] == '':\n",
        "    f.write(\"question: \" + question_cs + \"\\n\" +\n",
        "              \"answer: odpověď nenalezena\" + \"\\n\" + \n",
        "              \"correct answer: \" + correct_answer + \"\\n\\n\")\n",
        "    continue\n",
        "\n",
        "  # get the best doc\n",
        "  # get best answer from retriever according to reader\n",
        "  # get the best confidence\n",
        "  document = bestDocs[np.argmax(bestLogProbs, axis=0)]\n",
        "  answer = bestAnswers[np.argmax(bestLogProbs, axis=0)]\n",
        "\n",
        "  # translate the final answer\n",
        "  answer_en = answer\n",
        "  try:\n",
        "    answer =  translator.translate(answer, src='en', dest='cs').text\n",
        "  except IndexError:\n",
        "    pass\n",
        "\n",
        "  # convert to string to write to file\n",
        "  bestAnswers = (\";; \").join(bestAnswers)\n",
        "  bestLogProbs = (\";; \").join(str(v) for v in bestLogProbs)\n",
        "  bestSummedLogProbs = (\";; \").join(str(v) for v in bestSummedLogProbs)\n",
        "\n",
        "  # write the result to file\n",
        "  f.write(\"otázka č.\" + name + \": \" + question_cs + \"\\n\" +\n",
        "          \"::odpověď: \" + answer + \" / \" + answer_en + \"\\n\" + \n",
        "          \"::správná odpověď podle sqad : \" + correct_answer + \"\\n\\n\" +\n",
        "          bestAnswers + \"\\n\" +\n",
        "          bestLogProbs + \"\\n\" +\n",
        "          bestSummedLogProbs + \"\\n\\n\" +\n",
        "          # \"::sqad lemmatized : \" + lemmatized_answer + \"\\n\" +\n",
        "          \"----------------------------------------------------------------\\n\"+\n",
        "          \"získaný dokument: \" + document + \n",
        "          \"\\n----------------------------------------------------------------\\n\"+\n",
        "          \"----------------------------------------------------------------\"+\n",
        "          \"\\n\\n\")\n",
        "  \n",
        "  # controlprint\n",
        "  print(\"wrote: \" + name)\n",
        "\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8KuCxCtNFNo"
      },
      "source": [
        "# Ask a question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNffv4UPNITW"
      },
      "source": [
        "def find_answer(question, bm25_for_title_index, titles):\r\n",
        "  \"\"\"\r\n",
        "  finds the answer to the question\r\n",
        "  \"\"\"\r\n",
        "  question_cs = question # save czech question\r\n",
        "\r\n",
        "  # wiki search\r\n",
        "  documents = retrieve(question, bm25_for_title_index, titles)\r\n",
        "\r\n",
        "  # for saving the best results\r\n",
        "  bestAnswers = []\r\n",
        "  bestDocs = []\r\n",
        "  bestLogProbs = []\r\n",
        "\r\n",
        "  # iterate over retrieved paragraphs\r\n",
        "  for document in documents:\r\n",
        "\r\n",
        "    # strip whitespaces\r\n",
        "    document = document.strip()\r\n",
        "\r\n",
        "    # chceck if any document has been found for the question\r\n",
        "    if document == \"\":\r\n",
        "      continue;\r\n",
        "    try:\r\n",
        "      document_cs = document\r\n",
        "      document = translator.translate(document, src='cs', dest='en').text\r\n",
        "    except TypeError:\r\n",
        "      continue\r\n",
        "\r\n",
        "    # remove some trash\r\n",
        "    # TODO this not cool (in retriever)\r\n",
        "    if (document_cs.strip().startswith(\"Obrázky, zvuky či videa k tématu\")):\r\n",
        "      continue\r\n",
        "\r\n",
        "    # translate\r\n",
        "    question = translator.translate(question, src='cs', dest='en').text\r\n",
        "\r\n",
        "    #get answer -------------------------------------------\r\n",
        "    answers = get_answers(question, document)\r\n",
        "    print(answers)\r\n",
        "    log_conf = 0\r\n",
        "    answer = ''\r\n",
        "    for answer in answers:\r\n",
        "      if answer['text'] != '':\r\n",
        "        log_conf = answer['score']\r\n",
        "        answer = answer['text']\r\n",
        "        log_conf_summed = count_log_conf(answer, answers)\r\n",
        "        break\r\n",
        "    #######################################################\r\n",
        "\r\n",
        "    # save probs and answer\r\n",
        "    bestAnswers.append(answer)\r\n",
        "    bestLogProbs.append(log_conf_summed)\r\n",
        "    # save retrieved doc\r\n",
        "    bestDocs.append(document_cs)\r\n",
        "\r\n",
        "  ############################################################\r\n",
        "  # check if any answer was found\r\n",
        "  if len(bestLogProbs) == 0 or bestAnswers[np.argmax(bestLogProbs, axis=0)] == '':\r\n",
        "    return \"odpověď nenalezena\"\r\n",
        "\r\n",
        "  print(bestAnswers)\r\n",
        "  print(bestLogProbs)\r\n",
        "  # get the best doc\r\n",
        "  # get best answer from retriever according to reader\r\n",
        "  document = bestDocs[np.argmax(bestLogProbs, axis=0)]\r\n",
        "  answer = bestAnswers[np.argmax(bestLogProbs, axis=0)]\r\n",
        "\r\n",
        "  # translate the final answer\r\n",
        "  answer_en = answer\r\n",
        "  answer =  translator.translate(answer, src='en', dest='cs').text\r\n",
        "\r\n",
        "  return answer, answer_en, document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnyTmjiQkeKS"
      },
      "source": [
        "# build index for searching through wiki article titles\r\n",
        "bm25_for_title_index, titles = get_title_search_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KyVD2CDNhcy"
      },
      "source": [
        "warnings.filterwarnings(\"ignore\")\r\n",
        "\r\n",
        "question = \"Jak se jmenuje otec spisovatele Jiřího Muchy ?\"\r\n",
        "answer = find_answer(question, bm25_for_title_index, titles)\r\n",
        "\r\n",
        "if len(answer) != 3:\r\n",
        "  print(answer)\r\n",
        "else:\r\n",
        "  print(answer[0])\r\n",
        "  print(answer[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}